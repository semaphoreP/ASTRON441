{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numpy & Pandas\n",
    "\n",
    " (from Code/Astro) Authors: BJ Fulton and Sarah Blunt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy and Arrays\n",
    "\n",
    "Numpy is a powerful numeric library that is essential for anyone analyzing data with Python. Numpy is a huge package that can support a multitude of tasks. Numpy is also inextricably linked to SciPy, a powerful library for scientific computing with capabilities for fitting, linear algebra, machine learning, etc. Here we are just going to cover some of the basics of numpy, but I encourage you to check out the numpy documentation pages (https://numpy.org/doc/stable/) to get an idea of the variety of things you can do.\n",
    "\n",
    "Arrays are a data type which is fundamental to Numpy. In some ways Numpy arrays are like Python lists:\n",
    "- both are used for storing data/objects\n",
    "- both are mutable (i.e. you can change their elements)\n",
    "- items can be extracted from both using indexing and slicing\n",
    "- both can be iterated over\n",
    "\n",
    "However there are key aspects of arrays that make them very different:\n",
    "- most operators act on the elements of an array instead of the array as a whole\n",
    "- arrays can only hold data of a single type\n",
    "- arrays can efficiently store large amounts of data in memory\n",
    "- arrays are of fixed size in memory, whereas lists don't have fixed size. (Question: if arrays have fixed size, how do you think [numpy.append](https://numpy.org/doc/stable/reference/generated/numpy.append.html) works?)\n",
    "\n",
    "Numpy is well suited for astronomy as we often have fixed-sized data of a single type (e.g., 2D images, 1D spectra, 3D spectral datacubes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# create some sample lists\n",
    "xlist = [1, 2, 3, 4]\n",
    "ylist = [1, 4, 9, 16]\n",
    "\n",
    "# create some sample arrays\n",
    "x = np.array([1, 2, 3, 4])\n",
    "y = np.array([1, 4, 9, 16])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's check out the different behaviors between lists and arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xlist * 4)\n",
    "\n",
    "print(x * 4)\n",
    "\n",
    "print(x / 4)\n",
    "\n",
    "print(xlist / 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the list was repeated 4 times, whereas each element of the array was multiplied by 4 and the result ended up being the same length.\n",
    "\n",
    "Division works element-wise for arrays, but division is not defined and produces an error when performed on a list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterating, indexing, and slicing\n",
    "\n",
    "Iterating over a 1D array looks just like iterating over a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for val in xlist:\n",
    "    print(val)\n",
    "\n",
    "for val in x:\n",
    "    print(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterating an N-dimensional array will iterate over slices along the first dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.random.uniform(size=(5, 5))\n",
    "\n",
    "for val in y:\n",
    "    print(val)\n",
    "\n",
    "print()\n",
    "# you could accomplish the same thing like this (but it's less readible and marginally less efficient)\n",
    "for i in range(y.shape[0]):\n",
    "    val = y[i, :]\n",
    "    print(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also select subsets of the array using conditionals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x)\n",
    "xs = x[x < 3]\n",
    "print(xs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, setting an array equal to another does not create a new array (pass by reference). In other words, editing either array will modify the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x)\n",
    "\n",
    "# attempt to create a new array, z, that is a copy of x\n",
    "z = x\n",
    "\n",
    "# modify x\n",
    "x[3] = 10\n",
    "\n",
    "# z is modified too\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like for lists, you can use the copy method if you really need a new copy of the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x)\n",
    "z = x.copy()\n",
    "x[3] = 20\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hstack and vstack are useful to stitch together multiple arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hstack stitches together along the first dimension\n",
    "hstack = np.hstack((x, z))\n",
    "print(hstack)\n",
    "\n",
    "print()\n",
    "# vstack stitches along the last dimension\n",
    "vstack = np.vstack((x, z))\n",
    "print(vstack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best practices\n",
    "\n",
    "- If it's important that your code is fast, it's almost always better to avoid for loops when dealing with arrays. Use numpy operations!\n",
    "- If I'm working on a complicated problem and I'm unsure whether to use a loop or array operations, I usually write it up in a loop first so that I can conceptualize the problem easier, then convert later to remove as many loops as possible.\n",
    "- Loops are often more readable than list comprehensions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas Tables\n",
    "\n",
    "Pandas is a powerful data analysis package that provides tools for manipulating tabular data. This is particularly useful in many astronomical applications, such as spectroscopy, and time-series. Data is organized into rows and columns where the columns are named and recalled using arbitrary Python objects (strings are the most convenient). This is in contrast to Numpy arrays where columns can only be accessed using integer indices (however, also see [structured arrays](https://numpy.org/doc/stable/user/basics.rec.html)).\n",
    "\n",
    "Sorting, querying, merging, and aggregation are some of the most useful Pandas features, but this tutorial will only scratch the surface. See https://pandas.pydata.org/docs/ for the full documentation.\n",
    "\n",
    "\n",
    "Pandas is most useful for dealing with heterogeneous and/or large datasets, when merging or complex queries are needed, or if you have metadata associated with columns (e.g. strings as labels)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic units/objects in Pandas are the Series and DataFrame objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Lets create a sample Series object\n",
    "x = [1.0, 2.0, 4.4, 4.5, 8.8, 9.1, 8.7, 2.3, 2.4, 3.1, 5.9]\n",
    "s = pd.Series(x)\n",
    "\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We populated a `Series` starting from a list of floating point numbers. Notice that two columns are printed in the output. Every entry in a Series has a corresponding integer index; generally these indices are created automatically. The data type stored is printed below the `Series` itself. Series objects can only store data of a single type, but any data type can be stored.\n",
    "\n",
    "A `Series` is like a single column of data in a table. A `DataFrame` is the Pandas object that represents a full table. Each column in the table is a `Series`.\n",
    "\n",
    "There are several ways to construct a Pandas `DataFrame`, including from Numpy arrays, Python dictionaries, a list of `Series` objects, reading from a CSV, reading from a URL, etc.\n",
    "\n",
    "Let's first construct a single-column `DataFrame` from our series `s`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(s, columns=['sample'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jupyter has special support for displaying DataFrames, simply typing the variable name of a DataFrame at the end of the cell will present a nicely formatted view of the table.\n",
    "\n",
    "Let's add some more columns to our DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sample_base'] = df['sample'] // 1\n",
    "df['sample_plus1'] = df['sample'] + 1\n",
    "df['sample_squared'] = df['sample']**2\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we can access the values in a column using two different syntax."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also easily save/read Pandas DataFrames to/from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to a CSV file\n",
    "df.to_csv('demo.csv')\n",
    "\n",
    "# read back from the CSV we just saved\n",
    "df = pd.read_csv('demo.csv')\n",
    "\n",
    "# a variety of other formats are supported including JSON, ASCII, etc. Each format has its own read/write methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Practices:\n",
    "\n",
    "`numpy` is more memory efficient than `pandas`, but `pandas` is often helpful for organization. For example, if I have a set of data that has 50 data points, each with time, radial velocity, error, S-index value, H-alpha value, and starname, a `pandas` `DataFrame` will probably be easier to keep track of than a multi-dimensional numpy array, or several 1D arrays. If `pandas` sounds like it will make your life harder rather than easier, it's probably not worth using. \n",
    "\n",
    "Consider using `pandas` when your data are:\n",
    "- heterogeneous (e.g. a mix of strings, ints, and floats)\n",
    "- going to be combined with other similar data sets (e.g. I have one set of timeseries data, taken with one instrument, and another set of data from a second instrument, and I want to extract all data from both instruments)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activites (numpy)\n",
    "\n",
    "Work in groups of ~2.\n",
    "\n",
    "### Roles:\n",
    "- driver: types code (person whose brithday is coming up the soonest)\n",
    "- navigator: directs the driver what to type (can be more than 1 person)\n",
    "\n",
    "### Product:\n",
    "- Activity 1: plot of length vs time for both arrays and lists\n",
    "- Activity 2: answer & justification for each scenario\n",
    "\n",
    "## Activity #1 \n",
    "\n",
    "Let's see how much faster it is to work with Numpy arrays over Python lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# First we'll create a long list\n",
    "length = 10000000  # must be an int\n",
    "x = list(range(length))\n",
    "\n",
    "# now lets loop over all of the elements and add one then divide by two\n",
    "# we will also use the time package to time how long it takes\n",
    "t1 = time.time()\n",
    "for i in range(len(x)):\n",
    "    x[i] = (x[i] + 1) / 2\n",
    "t2 = time.time()\n",
    "\n",
    "print(\"Updated {:d} elements in {:4.3f} seconds.\".format(length, t2-t1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Change the length of the list and keep track of how long the calculation takes as a function of that length.\n",
    "\n",
    "1. Plot the time as a function of list length.\n",
    "\n",
    "1. Now construct a Numpy array from the list `x` and perform the same calculation for several different array lengths.\n",
    "\n",
    "1. Plot the calculation time as a function of array length and add this line to the plot created in step #2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity #2\n",
    "\n",
    "Should you use a for loop in each of the following scenarios? Why or why not?\n",
    "\n",
    "Scenario 1: I want to multiply each element in an array by 10.\n",
    "\n",
    "Scenario 2: I'm writing a quicklook reduction pipleine that will run in real time (so it needs to be as fast as possible). I need to convolve each pixel in an image with the same kernel function.\n",
    "\n",
    "Scenario 3: I'm writing an open-source data anlysis package that will be used and modified by many people. I have 10,000 images that I need to run the same set of functions on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More on Pandas Functionality \n",
    "(Continuation from above on details of Pandas features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now sort by the `sample_squared` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by='sample_squared')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the indices were re-ordered as well. The indices retain information about the original ordering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also select subsets of the data using conditionals similar to Numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = df[df['sample'] <= 4]\n",
    "q1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.groupby` method is used to create Pandas `DataFrameGroupBy` object which can be used to calculate statistics within the groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groups that share a common sample_base field\n",
    "g = df.groupby('sample_base')\n",
    "\n",
    "# count number of rows within each group\n",
    "print(g.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also merge DataFrames together using a common column.\n",
    "\n",
    "Lets create a second DataFrame from the same original list of numbers and calculate the `sample_base` field again. We will also calculate a new column called `sample_sqrt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(x, columns=['sample'])\n",
    "\n",
    "df2['sample_base'] = df2['sample'] // 1\n",
    "df2['sample_sqrt'] = np.sqrt(df2['sample'])\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can add this new column into the original DataFrame by matching up the values on a shared column. In this case we want to match up on the original `sample` column.\n",
    "\n",
    "Sometimes we have multiple DataFrames with one or more overlapping columns and we need to combine into a single DataFrame. This is where merging comes in.\n",
    "\n",
    "Merging is a powerful and complex subject. I frequently find myself [here](https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html) to lookup various functionalities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.merge(df, df2, on='sample', suffixes=['_original', '_new'])\n",
    "merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a column name appears in both DataFrames but is not the column that you are merging on, the strings defined in the `suffixes` argument will be appended to the end of the column names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Activity #3\n",
    "\n",
    "Lets load a couple files into a Pandas DataFrame and rearrange and merge them into a single file in a more useful format. `example_data/star_names.json` contains a list star names. If you're runing this notebook on google colab, you'll need to upload the files in codeastro/exampe_data here (click on the file button on the left, then right-click on sample_data, then upload). The `primary_name` column is the primary ID for the star. For each unique `primary_name` there are many `other_names` associated with it. Each `primary_name`+`other_name` combination is stored in a separate row.\n",
    "\n",
    "1. First load the file `example_data/star_names.json` into a Pandas DataFrame. The file is in JSON format so you might look into the `pandas.read_json` function.\n",
    "\n",
    "1. Group the DataFrame on the `primary_name` column and create a custom aggregation function that takes all of the values in the `other_name` column that have the same `primary_name` and converts them into a single string deliminated with a pipe (`|`).\n",
    "\n",
    "1. Load the `example_data/star_props.csv` file into a separate DataFrame and merge this with the grouped DataFrame from step #2.\n",
    "\n",
    "1. Save the result as a new CSV file. The resulting file should look like `example_data/stars_merged.csv`. You may also load this file into Pandas to see what the final DataFrame should look like before saving to a CSV."
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.9.5 ('codeastro')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "vscode": {
   "interpreter": {
    "hash": "70da8eaca2f829bebd9ae4bfee73e2015b5a57abadfaaa95753587bc60143f91"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
